---
layout: post
title:  "Discussão de artigos #4"
date:   09-04-2021
meeting:   09-04-2021
categories: workshops
type: paper-discussion
description: "* Attention is all you need"
hero_height: is-small
published: true
---

# Tema

Artigos relevantes na área de deep learning.

# Descrição

Essa mesa redonda propõe uma discussão sobre 1 artigo relevante para a área de Visão Computacional e Deep Learning. O artigo escolhido foi: 

* [**Attention is all you need**](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

    * **Authors**: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin

    * **Abstract**: The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.

    * [**Review information**](https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

<!---
# Discussão

<iframe style="width:660px;height:415px;"
    src="https://www.youtube.com/embed/a4XVqBzntUU" 
    allowfullscreen>
</iframe>
-->
